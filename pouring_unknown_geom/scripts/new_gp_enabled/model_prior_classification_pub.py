#!/usr/bin/env python
'''
When called, this function takes in the model edge message, then compares all of the 
stored pours from different container geometries. Given the top N (specified in call with default),
the errors in edge-profile approximated with these are normalized. These normalizations are then used as 
probabilities (summing to 1), in order to collectively use them for a mixture model.
profile edge extraction file layout:
  First extentions (edge profiles):
    autogenerated_#.npy
  Further extensions:
    autogenerated_#iteration_0_params.txt :: gives a) rotation speed, b) stop angle
    autogenerated_#iteration_0.text ::  (Main to load)  -> 1. num particles in container 2. max num particles 3. angle (rad) 4. time (sec)
    autogenerated_#iteration_0_wait_times.text :: two rows, 1. wait_time theta  2. value value
'''
import rospy, rospkg
import numpy as np, math
import sys, os
from std_srvs.srv import * #for Trigger
from pouring_msgs.msg import ContainerEdgeProfile, SelectedGPModels, GPVolumeModel, GPEdgeProfileSelectedTrain, TrainingContainerEdgeProfile
import threading

class RMSEArray(object):
  def __init__(self):
    self.rmse = []
    self.file_name = []
    self.volumes = []

class ModelPriorClassificationPub(object):
  """docstring for ModelPriorClassificationPub"""
  def __init__(self):
    #get parameters from server
    self.number_of_final_priors = rospy.get_param("number_of_final_priors", 10)
    self.number_profile_edge_points = rospy.get_param("num_profile_edge_points",128)
    self.thread_lock = threading.Lock() #.acquire() .release()
    self.profile_callback_msg = None
    self.profile_msg_obtained = False
    #To publish the selected models
    self.pub_selected_models = rospy.Publisher("gp_selected_models",SelectedGPModels,queue_size =1,latch=True)
    self.pub_selected_models_edge_profile = rospy.Publisher("gp_selected_models_edge_profile",GPEdgeProfileSelectedTrain,queue_size =1,latch=True)

    #data paths
    self.rospack = rospkg.RosPack()
    self.data_path_edge_profile_path = self.rospack.get_path("pouring_unknown_geom") + '/data/profile_edge_to_volume/simulated/sim_profile_points/' 
    self.data_path_volume_profile_path = self.rospack.get_path("pouring_unknown_geom") + '/data/profile_edge_to_volume/simulated/sim_volume_profile/'

  def ResetTrig(self,req):
    self.number_of_final_priors = rospy.get_param("number_of_final_priors", 10)
    self.number_profile_edge_points = rospy.get_param("num_profile_edge_points",128)
    self.profile_callback_msg = None
    self.profile_msg_obtained = False
    trig_resp = TriggerResponse()
    trig_resp.success = True
    trig_resp.message = "reset complete"
    return trig_resp

  def ProfileCallback(self,data):
    self.thread_lock.acquire()
    local_bool = self.profile_msg_obtained
    self.thread_lock.release()
    if local_bool == False:
      #callback hasn't been received yet
      self.thread_lock.acquire()
      self.profile_callback_msg = data
      self.profile_msg_obtained = True
      self.thread_lock.release()
    else:
      #callback ws previously recieved, pass
      pass

  def volume_sim_container_numerical(self,container_data=None):
    r_raw = container_data[0];
    h_raw = container_data[1];
    #1. for Npts, calculate N-1 dh segments, and corresponding N-1 r_avg consecutively
    r_avg_list = []
    dh_list = []
    for idx in range(0,len(r_raw)-1):
      rl = r_raw[idx]
      rh = r_raw[idx+1]
      hl = h_raw[idx]
      hh = h_raw[idx+1]
      dh = hh-hl
      r_avg = (rl+rh)/2.0
      r_avg_list.append(r_avg)
      dh_list.append(dh)
    #2. Find and sum volumes using dV = dh*pi*(r_avg**2)
    volume = 0.0
    for idx in range(len(dh_list)):
      volume += dh_list[idx] * np.pi*(r_avg_list[idx]**2)
    #convert from m^3 to ml
    volume = volume*1e6  #(1000L/m^2 * 1000ml/L)
    return volume
    '''
    FIX THIS, VOLUMES ARE TOO SMALL
    '''

  def rmse_calculator(self,training_data=None, test_data=None):
    #This takes in training and test data (requires that they be the same length: N)
    #given every point q_i = [h_i,r_i], obtian the rmse: sqrt ( 1/N sum_i (q_(train,i) - q_(test,i))**2 )
    #1. extract the data (all units must be in meters)
    r_test = test_data.radius;
    h_test = test_data.height;
    r_train = training_data[0];
    h_train = training_data[1];
    se = 0.0 #squared err
    for idx in range(len(r_test)):
      q_test = np.matrix([r_test[idx], h_test[idx]])
      q_train = np.matrix([r_train[idx], h_train[idx]])
      diff = q_test - q_train
      se += np.linalg.norm(diff)**2
    mse = se/float(len(r_test))
    rmse = np.sqrt(mse)
    return rmse

  def redact_edge_profile_file_list(self,edge_profile_file_list=None, volume_profile_file_list=None):
    #function searches for the files contained in volume file list as well (searches strings), reducing the list to those contained
    redacted_edge_profiles = []
    for edge_file in edge_profile_file_list:
      edge_file_base = edge_file[:-4]
      file_contained = False
      for vol_file in volume_profile_file_list:
        if edge_file_base in vol_file:
          file_contained = True
          redacted_edge_profiles.append(edge_file)
          break
    return redacted_edge_profiles

  def increasing_volume_function(self,Vdec=None):
    Vinc = [0.0]
    for idx in range(0,len(Vdec)-1):
      dV = np.abs(Vdec[idx] - Vdec[idx+1])
      Vcurr = Vinc[-1]
      Vinc.append(Vcurr+dV)
    return Vinc

  def Model_prior_class_main(self,req):
    self.thread_lock.acquire()
    local_bool = self.profile_msg_obtained
    self.thread_lock.release()

    if local_bool == True:
      #1. Obtain profile message
      self.thread_lock.acquire()
      local_profile_callback_msg = self.profile_callback_msg
      self.thread_lock.release()
      #2. Load all of the container profiles, ensure that each edge profile is described by a consistent number of points 'self.number_profile_edge_points'
      #2a. get names of all files
      files_edge_profiles = [f for f in os.listdir(self.data_path_edge_profile_path) if os.path.isfile(os.path.join(self.data_path_edge_profile_path,f))] #unique names for each is file[:-4]
      files_volume_profiles = [f for f in os.listdir(self.data_path_volume_profile_path) if os.path.isfile(os.path.join(self.data_path_volume_profile_path,f))] #for each above unique file name there is additional strings      
      #3. Determine which top M most closely match the observed profile using the rmse metric: 
      # sqrt ( 1/N sum_i (q_(train,i) - q_(test,i))**2 ) where q_i = [h_i,r_i] is the i'th point out of N in a profile
      # which allows comparison between containers. This is done for M containers, with a resultant rmse score for each.
      # Iterate through the edge profiles (first elem in radius, second is height, height is increasing order), same for container edge profile msg
      # For each, store in a list the name and rmse until the critial number is reached (list), 
      # then order the list wrt the rmse
      # finally, only add points if they are greater than the min rmse value in the list (and reorder each time) until the files are exhausted
      rmse_obj = RMSEArray()
      data_string = 'iteration_0.text' #with front file, this
      #filter file list to ensure only files that have volume curves are considered
      files_edge_profiles = self.redact_edge_profile_file_list(edge_profile_file_list=files_edge_profiles, volume_profile_file_list=files_volume_profiles)
      #Loop through and collect data:
      for curr_file in files_edge_profiles:
        curr_data = np.load(self.data_path_edge_profile_path+curr_file) #load the file
        #Find the rmse
        rmse = self.rmse_calculator(training_data=curr_data, test_data=local_profile_callback_msg)
        vol = self.volume_sim_container_numerical(container_data=curr_data)
        #Decide whether to add it to the list
        if len(rmse_obj.rmse) >= self.number_of_final_priors:
          #Determine if rmse is lower than the max value (last value)
          if rmse < np.max(rmse_obj.rmse):
            #If it is, then pop the last and add this new value
            argmax = np.argmax(rmse_obj.rmse)
            rmse_obj.rmse.pop(argmax)
            rmse_obj.file_name.pop(argmax)
            rmse_obj.volumes.pop(argmax)
            #now append
            rmse_obj.rmse.append(rmse)
            rmse_obj.file_name.append(curr_file[:-4])
            rmse_obj.volumes.append(vol)
          else:
            #continue
            pass
        else:
          #haven't reached critical number so simply add it to the list
          rmse_obj.file_name.append(curr_file[:-4])
          rmse_obj.rmse.append(rmse)
          rmse_obj.volumes.append(vol)
      #4. The containers are ranked by their rmse score, top M are chosen (specified by 'number_of_final_priors'), these scores are then 
      # normalized to sum to 1.0
      rmse_sum = np.sum(rmse_obj.rmse)
      prob_mid = [np.float(rmse_sum)/np.float(rr) for rr in rmse_obj.rmse] #flip the probabiliy so lowest err is highest probability
      prob_mid_sum = np.sum(prob_mid)
      prob = [np.float(rr)/np.float(prob_mid_sum) for rr in prob_mid]
      #prob = [np.float(rr)/np.float(rmse_sum) for rr in rmse_obj.rmse]
      #5. These top ranked containers and their probability scores are then published on a latch message for later use, along with a container id tag for 
      #multiple pours
      gp_selected_models = SelectedGPModels()
      gp_selected_models.header.stamp = rospy.Time.now()
      gp_selected_models.lowest_model_rmse = np.min(rmse_obj.rmse)
      gp_selected_models_edge_profile = GPEdgeProfileSelectedTrain()
      gp_selected_models_edge_profile.header.stamp = rospy.Time.now()
      for idx in range(len(rmse_obj.file_name)):
        file = rmse_obj.file_name[idx]
        #load the volume profile to use
        curr_vol_data = np.loadtxt(self.data_path_volume_profile_path +file+data_string)
        th = curr_vol_data[:,2]
        V_normed = curr_vol_data[:,0]/curr_vol_data[0,1]  #THIS NEEDS TO BE CONVERTED TO ML
        V = rmse_obj.volumes[idx]*V_normed  #this scales to the estimated volume of the simulated container
        V_inc = self.increasing_volume_function(Vdec=V)
        #The 1000 makes this volume in ml instead of liters
        #store the volume profile
        curr_model= GPVolumeModel()
        curr_model.V = V_inc
        curr_model.th = th
        curr_model.perc_mix_model = prob[idx]#store the associated probability
        curr_model.rmse_value = rmse_obj.rmse[idx]#store the associated probability
        gp_selected_models.gp_volume_models.append(curr_model)
        #Now for edge profile storage
        curr_profile_data = np.load(self.data_path_edge_profile_path + file+'.npy')
        curr_model_edge_profile = TrainingContainerEdgeProfile()
        curr_model_edge_profile.radius = curr_profile_data[0]
        curr_model_edge_profile.height = curr_profile_data[1]
        curr_model_edge_profile.perc_mix_model = prob[idx]
        curr_model_edge_profile.container_height_m = curr_profile_data[1][-1]
        gp_selected_models_edge_profile.training_containers.append(curr_model_edge_profile)
      #Publish the selected models
      self.pub_selected_models.publish(gp_selected_models)
      self.pub_selected_models_edge_profile.publish(gp_selected_models_edge_profile)
    #6. Return the trigger response
    trig_resp = TriggerResponse()
    if self.profile_msg_obtained:
      trig_resp.success = True
      trig_resp.message = "profile obtained, model classified and published"
    else:
      trig_resp.success = False
      trig_resp.message = "profile was not obtained"
    return trig_resp


def main():
  rospy.init_node('model_prior_classificaton_pub');
  cls_obj = ModelPriorClassificationPub();
  sub = rospy.Subscriber("~container_edge_profile_pub_msg",ContainerEdgeProfile, cls_obj.ProfileCallback); #add ~ and remap to launch later
  serv_pub = rospy.Service("~model_prior_classificaton_serv", Trigger, cls_obj.Model_prior_class_main);
  serv_reset = rospy.Service("~reset_model_prior_classification_serv",Trigger, cls_obj.ResetTrig);
  rospy.spin()



if __name__ == '__main__':
  main()

'''
TODO: [DONE]
1. fix volume integration (too small, orders of magnitude and not liters/ml problem)
2. make volume profiles increasing functions :: Is this a problem (what happens when you start pouring with non V_init = 0) how does this compare?
shifting was performed in previous methods to handle this?, the increasing volume curve can find the volume function that is closest in angle to your
current angle (start angle), then subtract the corresponding increasing volume from all volumes to shift all the training data down for V=0 axis intersect
This occurs before you use the GP

to run: 
first run
  roslaunch pouring_unknown_geom container_profile_extractor.launch 
  rosrun pouring_unknown_geom container_edge_query.py
then run 
  rosrun pouring_unknown_geom model_prior_classification_pub.py
then call the initiating service
  rosservice call /model_prior_classificaton_serv
'''
